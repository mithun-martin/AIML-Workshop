{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFJMMsfsOwydkroyBY27XG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mithun-martin/AIML-Workshop/blob/main/DAY2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MiqOgvaQklU"
      },
      "outputs": [],
      "source": [
        "#KERAS BASICS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TYPE OF APIS\n",
        "#1.SEQUENTIAL API = MODEL IS CREATED LAYER BY LAYER\n",
        "#2.FUNCTIONAL API = MODEL IS CREATED ALL AT ONCE\n"
      ],
      "metadata": {
        "id": "Fz4QoQmFUouN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL BUILDING STEPS IN KERAS\n",
        "#1.GATHER DATA\n",
        "#2.CREATING NN ARCHITECTURE USING SEQUENTIAL API:\n",
        "        #INPUT\n",
        "        #HIDDEN = INPUT SHAPE,ACTIVATION FUNCTION\n",
        "        #OUTPUT = ACTIVATION FUNCTION\n",
        "#3.COMPILE:here we define the LOSS FUNCTIONS,OPTIMIZERS,METRICS\n",
        "#4.FIT THE MODEL = TRAINING"
      ],
      "metadata": {
        "id": "VU4f1_2ZVSC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ACTIVATION FUNCTION WE USE INSIDE REGRESSION AND CLASSIFICATION\n",
        "#details given in day2 notes"
      ],
      "metadata": {
        "id": "qesgy1FBVprE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation Functions\n",
        "# Regression\n",
        "# Hidden Layers : ReLU(preferred choice), LeakyReLU, tanh\n",
        "# Output Layer : Linear Activation(No Activation Function)\n",
        "\n",
        "# Classification\n",
        "# -Binary Classification\n",
        "# Hidden Layers : ReLU(preferred choice), LeakyReLU, tanh\n",
        "# Output Layer : Sigmoid\n",
        "\n",
        "# -Multi-Class Classification\n",
        "# Hidden Layers : ReLU(preferred choice), LeakyReLU, tanh\n",
        "# Output Layer : Softmax"
      ],
      "metadata": {
        "id": "4gnXfXTjb9dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU(Rectified Linear Unit)\n",
        "# Formula : f(x) = max(0,x)\n",
        "# When to use: Default choice for most hidden layers\n",
        "\n",
        "# Leaky ReLU\n",
        "# Formula : f(x) = max(ax,x) (where a is a small constant, usually 0.01)\n",
        "# When to use: If you find ReLU causing too many dead neurons, try Leaky ReLU\n",
        "\n",
        "# Tanh(Hyperbolic Tangent)\n",
        "# Formula : f(x) = tanh(x) = (e^x - e^(-x)) / (e^x + e^(-x))\n",
        "# When to use: In shallow networks or when you need outputs between -1 and 1\n",
        "\n",
        "# Sigmoid\n",
        "# Formula : f(x) = 1 / (1 + e^(-x))\n",
        "# When to use: When you're dealing with two classes (eg: yes/no, true/false, positive/negative, etc.)\n",
        "\n",
        "# Softmax\n",
        "# Formula : f(x_i) = e^(x_i) / Î£e^(x_j) (for each class i)\n",
        "# When to use: For multi-class classification problems (eg: classifying digits 0-9)"
      ],
      "metadata": {
        "id": "jsL-ew2GcJBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#error finding\n",
        "#MSE,MAE,BINARY CROSS ENTROPY"
      ],
      "metadata": {
        "id": "2XRS7siOcjLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_acual = ([1000,2000,3000])\n",
        "#after pred and gng trhroug many algos\n",
        "y_pred = ([1100,1950,3000])"
      ],
      "metadata": {
        "id": "6J1fRCb0cmRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = np.subtract(y_acual,y_pred)\n",
        "error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVx6vwbxcvfS",
        "outputId": "00baf2ce-01b3-4519-8f5a-fb3c939f880e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-100,   50,    0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sq_error = np.square(error)\n",
        "sq_error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-yosXVWdGFE",
        "outputId": "60e75ce5-29ff-4a71-af03-8754692deb04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10000,  2500,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(sq_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX2LSNkYdQDS",
        "outputId": "e9619735-bb21-4e68-94e6-c0e7c4775776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4166.666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
        "np.mean(np.absolute(np.subtract(y_acual,y_pred)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuvV-9-sdvbH",
        "outputId": "d85e5c15-abbc-41cb-fb34-2b1d872342c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y_acual,y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38HrAjl_esRZ",
        "outputId": "965799fd-3b70-4d1e-f4be-73c341bc91c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4166.666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_acual,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpLESN_Pe51T",
        "outputId": "740988da-c9bd-4a0e-d905-be6014ab8fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BCE\n",
        "p = [1,1,1,1,0,0,0,0] #actual values"
      ],
      "metadata": {
        "id": "aoKvbSl_fbeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = [0.8,0.75,0.7,0.5,0.3,0.3,0.2,.1] #predicted values\n"
      ],
      "metadata": {
        "id": "nJr1J9aVflt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "def binary_ce(p,q):\n",
        "       return -((p * log(q)) + ((1 - p) * log(1 - q)))\n"
      ],
      "metadata": {
        "id": "xk1ezHZTgAUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for i in range(len(p)):\n",
        "    ce = binary_ce(p[i], q[i])\n",
        "    result.append(ce)\n",
        "\n",
        "mean_ce = np.mean(result)\n",
        "mean_ce\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9z5_O3QgECd",
        "outputId": "b83bc159-203c-48bc-b950-f6b55f346e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.32531271288927116"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gmg 2 work with keras now"
      ],
      "metadata": {
        "id": "x2Cv9CYGqUed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "auLF0aJFqWJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "40uurJGYqZxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gng 2 load dataset mnist and stoering in train test forat"
      ],
      "metadata": {
        "id": "jEnBQvllqdYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "vLVlH0qcqpwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape,y_train.shape,x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keFpcrJlq_xc",
        "outputId": "2e30c937-5216-4c91-cb8f-3fa8804c7b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#60k images for us to train the model"
      ],
      "metadata": {
        "id": "bzWEAx_DrV7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10k images for evaluating the model....we have 784 pixels in 1 image for this dataset that ehy shows 28X28"
      ],
      "metadata": {
        "id": "YnifFMMSrfyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aaQO3yRrsS55",
        "outputId": "9ed21a25-e345-46bc-da25-b35b45f4cc8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
              "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
              "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
              "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
              "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
              "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
              "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
              "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
              "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
              "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
              "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
              "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
              "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-c4797cc1-074a-4628-8e59-2d18c251ce94\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
              "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
              "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
              "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
              "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
              "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
              "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
              "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
              "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
              "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
              "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
              "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
              "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-c4797cc1-074a-4628-8e59-2d18c251ce94 button').onclick = (e) => {\n",
              "        document.querySelector('#id-c4797cc1-074a-4628-8e59-2d18c251ce94').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-c4797cc1-074a-4628-8e59-2d18c251ce94 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "#reshaping sisnce input layer neded to be in 1d\n",
        "#so we changed from 2d to 1d"
      ],
      "metadata": {
        "id": "eyUOcgjUsXGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOuXxchnszga",
        "outputId": "40f9d3fe-2d65-4e5e-afb5-4b7a3a1a9c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[1] #comparewoth the earlier x[1] which was in 2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "my19-iEVtBnm",
        "outputId": "1d8bd695-913f-4348-d42f-9e6b657f8402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 159, 253,\n",
              "       159,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238,\n",
              "       252, 252, 252, 237,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  54,\n",
              "       227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,\n",
              "        60, 224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0, 163, 252, 252, 252, 253, 252, 252,  96, 189, 253, 167,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  51, 238, 253, 253, 190, 114, 253, 228,  47,  79, 255,\n",
              "       168,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  48, 238, 252, 252, 179,  12,  75, 121,  21,   0,\n",
              "         0, 253, 243,  50,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,  38, 165, 253, 233, 208,  84,   0,   0,   0,\n",
              "         0,   0,   0, 253, 252, 165,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,  28,   0,\n",
              "         0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  76, 246, 252,\n",
              "       112,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 252,\n",
              "       148,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85,\n",
              "       252, 230,  25,   0,   0,   0,   0,   0,   0,   0,   0,   7, 135,\n",
              "       253, 186,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,  85, 252, 223,   0,   0,   0,   0,   0,   0,   0,   0,   7,\n",
              "       131, 252, 225,  71,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  85, 252, 145,   0,   0,   0,   0,   0,   0,   0,\n",
              "        48, 165, 252, 173,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,   0,\n",
              "         0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,\n",
              "        85, 178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 252, 252, 252,\n",
              "       229, 215, 252, 252, 252, 196, 130,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  28, 199,\n",
              "       252, 252, 253, 252, 252, 233, 145,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,  25, 128, 252, 253, 252, 141,  37,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to change dtatype"
      ],
      "metadata": {
        "id": "8MgX7bLMtCSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n"
      ],
      "metadata": {
        "id": "FpNn8lQltodr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "#ask chatgpt y\n",
        "x_train[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lORyddePtxLk",
        "outputId": "e7ffda77-d99a-4ff2-e3b0-9f486fc75428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
              "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
              "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
              "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
              "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
              "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
              "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
              "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
              "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
              "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
              "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
              "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
              "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
              "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
              "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
              "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
              "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
              "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
              "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=10\n",
        "\n",
        "y_train[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pLAiAO2uK8V",
        "outputId": "2cf46d32-2225-4b4b-a3e8-0f21afc37cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "[0,0,0,0,0,1,0,0,0,0]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3u-xElfuTXz",
        "outputId": "943020b9-7d12-4525-ede7-ec8d482afc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.flatten()  # Ensure y_train is 1D\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "y_test=keras.utils.to_categorical(y_test,num_classes)\n"
      ],
      "metadata": {
        "id": "xGlrzprYud2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vyZ8BtZuljJ",
        "outputId": "6c0d177c-0d58-4852-d7f5-31281da4d969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1xxIsHZvLw2",
        "outputId": "eb0c6ece-f988-4286-e402-34744f6e6efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(64,activation='relu',input_shape=(784,)))  # Hidden Layer 1\n",
        "model.add(Dense(64,activation='relu'))  # Hidden Layer 2\n",
        "model.add(Dense(10,activation='softmax'))  # Output Layer\n"
      ],
      "metadata": {
        "id": "NYMV9XulwVnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "JjvYOGSUwf3e",
        "outputId": "3e14f580-085d-429b-c562-d9555e88366c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ââââââââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââââ³ââââââââââââââââââ\n",
              "â\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â dense_3 (\u001b[38;5;33mDense\u001b[0m)                      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â          \u001b[38;5;34m50,240\u001b[0m â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dense_4 (\u001b[38;5;33mDense\u001b[0m)                      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â           \u001b[38;5;34m4,160\u001b[0m â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dense_5 (\u001b[38;5;33mDense\u001b[0m)                      â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  â             \u001b[38;5;34m650\u001b[0m â\n",
              "ââââââââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââââââââ\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ââââââââââââââââââââââââââââââââââââââââ³ââââââââââââââââââââââââââââââ³ââââââââââââââââââ\n",
              "â<span style=\"font-weight: bold\"> Layer (type)                         </span>â<span style=\"font-weight: bold\"> Output Shape                </span>â<span style=\"font-weight: bold\">         Param # </span>â\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â          <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â\n",
              "ââââââââââââââââââââââââââââââââââââââââ¼ââââââââââââââââââââââââââââââ¼ââââââââââââââââââ¤\n",
              "â dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  â             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> â\n",
              "ââââââââââââââââââââââââââââââââââââââââ´ââââââââââââââââââââââââââââââ´ââââââââââââââââââ\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,050\u001b[0m (215.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,050</span> (215.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,050\u001b[0m (215.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,050</span> (215.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Every neuron passes its connection to the next neuron.\n",
        "# Initially, there were 64 neurons in the hidden layers, while the output layer has only 10 neurons.\n",
        "# Parameters (params) refer to weights and biases."
      ],
      "metadata": {
        "id": "ib5DKt88xjvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model with categorical cross-entropy loss for multi-class classification.\n",
        "# Using RMSprop optimizer with a learning rate of 0.001.\n",
        "# Tracking accuracy as the evaluation metric.\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Setting batch size to 32 and training for 30 epochs.\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "# Training the model using training data.\n",
        "# Using a batch size of 32 and validating on test data after each epoch.\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "                    verbose=1, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUdWVNTZxkR0",
        "outputId": "4651a261-5bd0-4d69-93e3-596f47b3e979"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8657 - loss: 0.4712 - val_accuracy: 0.9532 - val_loss: 0.1563\n",
            "Epoch 2/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9600 - loss: 0.1322 - val_accuracy: 0.9644 - val_loss: 0.1118\n",
            "Epoch 3/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.0950 - val_accuracy: 0.9691 - val_loss: 0.0985\n",
            "Epoch 4/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.0747 - val_accuracy: 0.9713 - val_loss: 0.0932\n",
            "Epoch 5/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0628 - val_accuracy: 0.9736 - val_loss: 0.0984\n",
            "Epoch 6/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9833 - loss: 0.0552 - val_accuracy: 0.9750 - val_loss: 0.0884\n",
            "Epoch 7/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0469 - val_accuracy: 0.9766 - val_loss: 0.0966\n",
            "Epoch 8/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0463 - val_accuracy: 0.9741 - val_loss: 0.0998\n",
            "Epoch 9/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0394 - val_accuracy: 0.9726 - val_loss: 0.1059\n",
            "Epoch 10/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0353 - val_accuracy: 0.9763 - val_loss: 0.1029\n",
            "Epoch 11/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0313 - val_accuracy: 0.9726 - val_loss: 0.1293\n",
            "Epoch 12/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0275 - val_accuracy: 0.9721 - val_loss: 0.1283\n",
            "Epoch 13/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0269 - val_accuracy: 0.9751 - val_loss: 0.1210\n",
            "Epoch 14/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0252 - val_accuracy: 0.9729 - val_loss: 0.1418\n",
            "Epoch 15/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0223 - val_accuracy: 0.9731 - val_loss: 0.1331\n",
            "Epoch 16/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0225 - val_accuracy: 0.9738 - val_loss: 0.1506\n",
            "Epoch 17/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0181 - val_accuracy: 0.9753 - val_loss: 0.1432\n",
            "Epoch 18/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0155 - val_accuracy: 0.9730 - val_loss: 0.1564\n",
            "Epoch 19/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0153 - val_accuracy: 0.9764 - val_loss: 0.1483\n",
            "Epoch 20/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0140 - val_accuracy: 0.9761 - val_loss: 0.1564\n",
            "Epoch 21/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0137 - val_accuracy: 0.9759 - val_loss: 0.1514\n",
            "Epoch 22/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0121 - val_accuracy: 0.9756 - val_loss: 0.1582\n",
            "Epoch 23/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0103 - val_accuracy: 0.9765 - val_loss: 0.1677\n",
            "Epoch 24/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0109 - val_accuracy: 0.9786 - val_loss: 0.1686\n",
            "Epoch 25/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0101 - val_accuracy: 0.9754 - val_loss: 0.1844\n",
            "Epoch 26/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0083 - val_accuracy: 0.9747 - val_loss: 0.1873\n",
            "Epoch 27/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 0.9764 - val_loss: 0.2060\n",
            "Epoch 28/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0074 - val_accuracy: 0.9774 - val_loss: 0.1818\n",
            "Epoch 29/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 0.9779 - val_loss: 0.1888\n",
            "Epoch 30/30\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9762 - val_loss: 0.2145\n"
          ]
        }
      ]
    }
  ]
}